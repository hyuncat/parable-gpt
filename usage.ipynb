{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8705361",
   "metadata": {},
   "source": [
    "# ParableGPT\n",
    "**Author:** Sarah Hong\n",
    "\n",
    "A large language model, based off Meta's open-source *Llama 3.1-8B-Instruct*, which uses a corpus of various religious texts to generate parables across different cultural traditions.\n",
    "\n",
    "A project for Brian Greene's *Origins and Meaning* course, taken Fall 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc951c",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Corpus\n",
    "\n",
    "We will be analyzing texts from:\n",
    "- Bible - Christianity\n",
    "- Dhammapada - Buddhism\n",
    "- Qur'an - Islam\n",
    "- Tao Te Ching - Daoism / Confucianism\n",
    "\n",
    "These are sourced from https://github.com/Traves-Theberge/sacred-scriptures-mcp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188b3bc",
   "metadata": {},
   "source": [
    "### Step 1.1: Prepare the Bible and Qur'an\n",
    "\n",
    "We downloaded the Bible and Qur'an in JSON file format, but now we stride through in more meaning-rich chunks (say 12 verses per chunk), move over 8 verses, and add them as a chunk, and repeat until we iterate through the entire JSON. We return a list of 'chunks', dictionaries containing information in the format we'll ultimately write to our database in: containing `id`, `text`, and `metadata` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d51705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_bible_chunks() -> list[dict]:\n",
    "    # prepare data and create the chroma database\n",
    "    BIBLE_JSON = Path(\"./corpus/bible.json\")\n",
    "    bible = json.loads(BIBLE_JSON.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    W = 12 # window\n",
    "    H = 8 # hop\n",
    "\n",
    "    chunks: list[dict] = []\n",
    "    for book, chapters in bible.items():\n",
    "        for chap, verses in chapters.items():\n",
    "            chap = int(chap)\n",
    "            v_nums = sorted(int(v) for v in verses.keys())\n",
    "            v_texts = [(v, verses[str(v)].strip()) for v in v_nums if verses[str(v)].strip()]\n",
    "\n",
    "            for i in range(0, len(v_texts), H):\n",
    "                # chunk the verses together\n",
    "                chunked_verses = v_texts[i:i+W]\n",
    "                if not chunked_verses:\n",
    "                    continue\n",
    "\n",
    "                # retrieve relevant metadata\n",
    "                v_start = chunked_verses[0][0] # get the verse number of the start\n",
    "                v_end = chunked_verses[-1][0] # and end\n",
    "                text = \" \".join(t for _, t in chunked_verses).strip()\n",
    "\n",
    "                chunk_metadata = {\n",
    "                    # universal metadata\n",
    "                    \"tradition\": \"christianity\",\n",
    "                    \"collection\": \"bible\",\n",
    "                    \"language\":  \"english\",\n",
    "                    # bible-specific metadata\n",
    "                    \"book\": book,\n",
    "                    \"chapter\": chap,\n",
    "                    \"start_verse\": v_start,\n",
    "                    \"end_verse\": v_end,\n",
    "                } # create the final chunk to write to our jsonl file\n",
    "                final_chunk = {\n",
    "                    \"id\": f\"{book}_{chap}_{v_start}_{v_end}\",\n",
    "                    \"text\": text,\n",
    "                    \"metadata\": chunk_metadata,\n",
    "                }\n",
    "                chunks.append(final_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4421193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_quran_chunks() -> list[dict]:\n",
    "    # prepare data and create the chroma database\n",
    "    QURAN_JSON = Path(\"./corpus/quran.json\")\n",
    "    quran = json.loads(QURAN_JSON.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    W = 12 # window\n",
    "    H = 8 # hop\n",
    "\n",
    "    chunks: list[dict] = []\n",
    "    for surah, verses in quran.items():\n",
    "            v_texts = [(int(v['chapter']), int(v['verse']), v['text'].strip()) for v in verses]\n",
    "\n",
    "            for i in range(0, len(v_texts), H):\n",
    "                # chunk the verses together\n",
    "                chunked_verses = v_texts[i:i+W]\n",
    "                if not chunked_verses:\n",
    "                    continue\n",
    "\n",
    "                # retrieve relevant metadata\n",
    "                chap = chunked_verses[0][0] # get the chapter number of the start\n",
    "                v_start = chunked_verses[0][1] # get the verse number of the start\n",
    "                v_end = chunked_verses[-1][1] # and end\n",
    "                text = \" \".join(t for _, _, t in chunked_verses).strip()\n",
    "\n",
    "                chunk_metadata = {\n",
    "                    # universal metadata\n",
    "                    \"tradition\": \"islam\",\n",
    "                    \"collection\": \"quran\",\n",
    "                    \"language\":  \"english\",\n",
    "                    # quran-specific metadata\n",
    "                    \"surah\": surah,\n",
    "                    \"chapter\": chap,\n",
    "                    \"start_verse\": v_start,\n",
    "                    \"end_verse\": v_end,\n",
    "                } # create the final chunk to write to our jsonl file\n",
    "                final_chunk = {\n",
    "                    \"id\": f\"{surah}_{chap}_{v_start}_{v_end}\",\n",
    "                    \"text\": text,\n",
    "                    \"metadata\": chunk_metadata,\n",
    "                }\n",
    "                chunks.append(final_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977cb024",
   "metadata": {},
   "source": [
    "### Step 1.2: Prepare the Dhammapada and Tao Te Ching\n",
    "\n",
    "The Dhammapada and Tao Te Ching are in a slightly different formats, so we parse the JSON differently. Moreover, each chapter is its own self-contained 'parable,' so we don't enforce a strict `W` or `H` and go based off the built-in sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dda4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_dhammapada_chunks() -> list[dict]:\n",
    "    \"\"\"Prepare chunks of the Dhammapada text for processing.\n",
    "    Returns a list of dictionaries, each containing the text chunk and its metadata.\"\"\"\n",
    "    # prepare data and create the chroma database\n",
    "    DHAMMA_JSON = Path(\"./corpus/dhammapada.json\")\n",
    "    dhammapada = json.loads(DHAMMA_JSON.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    chunks: list[dict] = []\n",
    "    for chapter in dhammapada['chapters']:\n",
    "        # get relevant metadata\n",
    "        i = chapter['number']\n",
    "        title = chapter.get('title_english', None) or chapter.get('title', f\"Chapter {i}\")\n",
    "        verse_range = chapter['verse_range']\n",
    "        verses = [v['english'] for v in chapter['verses']]\n",
    "        text = \" \".join(verses).strip()\n",
    "\n",
    "        metadata = {\n",
    "            # universal metadata\n",
    "            \"tradition\": \"buddhism\",\n",
    "            \"collection\": \"dhammapada\",\n",
    "            \"language\":  \"english\",\n",
    "            # dhammapada-specific metadata\n",
    "            \"chapter\": title,\n",
    "            \"start_verse\": verse_range[0],\n",
    "            \"end_verse\": verse_range[1],\n",
    "        } # create the final chunk to write to our jsonl file\n",
    "        final_chunk = {\n",
    "            \"id\": f\"dhammapada_{i}_{verse_range[0]}_{verse_range[1]}\",\n",
    "            \"text\": text,\n",
    "            \"metadata\": metadata,\n",
    "        }\n",
    "        chunks.append(final_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e1ffc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import re\n",
    "\n",
    "def prepare_tao_chunks() -> list[dict[str, Any]]:\n",
    "    \"\"\"Prepare chunks of Tao Te Ching text. One chunk per chapter.\"\"\"\n",
    "    TAO_JSON = Path(\"./corpus/tao_te_ching.json\")\n",
    "    tao_te_ching = json.loads(TAO_JSON.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    chunks: list[dict[str, Any]] = []\n",
    "\n",
    "    def _chapter_num(ch_key: str) -> int:\n",
    "        m = re.search(r\"(\\d+)\", ch_key)\n",
    "        if not m:\n",
    "            raise ValueError(f\"Could not parse chapter number from key: {ch_key}\")\n",
    "        return int(m.group(1))\n",
    "    \n",
    "    for ch_key, ch_content in tao_te_ching.items():\n",
    "        ch_num = _chapter_num(ch_key)\n",
    "        text = ch_content['Verse'].strip()\n",
    "\n",
    "        metadata = {\n",
    "            # universal metadata\n",
    "            \"tradition\": \"taoism\",\n",
    "            \"collection\": \"tao_te_ching\",\n",
    "            \"language\":  \"english\",\n",
    "            # tao-specific metadata\n",
    "            \"chapter\": ch_num,\n",
    "        }\n",
    "        final_chunk = {\n",
    "            \"id\": f\"tao_te_ching_{ch_num}\",\n",
    "            \"text\": text,\n",
    "            \"metadata\": metadata,\n",
    "        }\n",
    "        chunks.append(final_chunk)\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ddd27",
   "metadata": {},
   "source": [
    "### Step 1.3: Write the chunks to ChromaDB\n",
    "\n",
    "[ChromaDB](https://www.trychroma.com/) is a fast, serverless vector database which is commonly used for semantic similarity search between a given `topic` and your corpus. The embedding models used to translate words into vectors can be arbitrarily swapped as needed. ChromaDB uses a clever indexing system to quickly enable cosine similarity comparisons across billions of different embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e80f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def index_corpus(chunks: list[dict], collection_name: str, \n",
    "                 db_path: str=\"./corpus/chroma_db\", \n",
    "                 embedder_model: str=\"all-MiniLM-L6-v2\",\n",
    "                 batch_size: int=64, force: bool=False):\n",
    "    \"\"\"Index the given chunks into a ChromaDB collection.\n",
    "\n",
    "    Args:\n",
    "        chunks (list[dict]): List of chunks to index.\n",
    "        collection_name (str): Name of the ChromaDB collection.\n",
    "        db_path (str): Path to the ChromaDB database.\n",
    "        embedder_model (str): SentenceTransformer model name for embeddings.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(db_path)\n",
    "\n",
    "    if force:\n",
    "        try:\n",
    "            client.delete_collection(name=collection_name)\n",
    "            print(f\"Deleted existing collection '{collection_name}'\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # create collection\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "    embedder = SentenceTransformer(embedder_model)\n",
    "\n",
    "    ids = [c['id'] for c in chunks]\n",
    "    texts = [c['text'] for c in chunks]\n",
    "    metadatas = [c['metadata'] for c in chunks]\n",
    "\n",
    "    def _batched(seq, size):\n",
    "        for i in range(0, len(seq), size):\n",
    "            yield seq[i:i+size]\n",
    "\n",
    "    total_batches = (len(chunks) + batch_size-1) // batch_size\n",
    "\n",
    "    for ids, docs, metas in tqdm(\n",
    "        zip(\n",
    "            _batched(ids, batch_size),\n",
    "            _batched(texts, batch_size),\n",
    "            _batched(metadatas, batch_size),\n",
    "        ), \n",
    "        total=total_batches,\n",
    "        desc=f\"Indexing '{collection_name}'\",\n",
    "        unit=\"batch\"\n",
    "    ):  # embed in batches (default size 64)\n",
    "        embeddings = embedder.encode(docs, normalize_embeddings=True).tolist()\n",
    "        collection.add(\n",
    "            ids=ids,\n",
    "            documents=docs,\n",
    "            metadatas=metas,\n",
    "            embeddings=embeddings,\n",
    "        )\n",
    "\n",
    "    print(f\"Indexed {len(chunks)} chunks into collection '{collection_name}' at '{db_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f80160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing 'tao_te_ching': 100%|██████████| 2/2 [00:00<00:00,  2.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 81 chunks into collection 'tao_te_ching' at './corpus/chroma_db'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run the above scripts\n",
    "bible_chunks = prepare_bible_chunks()\n",
    "dhamma_chunks = prepare_dhammapada_chunks()\n",
    "quran_chunks = prepare_quran_chunks()\n",
    "tao_chunks = prepare_tao_chunks()\n",
    "\n",
    "index_corpus(\n",
    "    chunks=bible_chunks,\n",
    "    collection_name=\"bible\",\n",
    "    db_path=\"./corpus/chroma_db\",\n",
    "    embedder_model=\"all-MiniLM-L6-v2\",\n",
    "    batch_size=64,\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "index_corpus(\n",
    "    chunks=dhamma_chunks,\n",
    "    collection_name=\"dhammapada\",\n",
    "    db_path=\"./corpus/chroma_db\",\n",
    "    embedder_model=\"all-MiniLM-L6-v2\",\n",
    "    batch_size=64,\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "index_corpus(\n",
    "    chunks=quran_chunks,\n",
    "    collection_name=\"quran\",\n",
    "    db_path=\"./corpus/chroma_db\",\n",
    "    embedder_model=\"all-MiniLM-L6-v2\",\n",
    "    batch_size=64,\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "index_corpus(\n",
    "    chunks=tao_chunks,\n",
    "    collection_name=\"tao_te_ching\",\n",
    "    db_path=\"./corpus/chroma_db\",\n",
    "    embedder_model=\"all-MiniLM-L6-v2\",\n",
    "    batch_size=64,\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987402b6",
   "metadata": {},
   "source": [
    "## Step 2: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "We use Retrieval-Augmented Generation (RAG) to enrich the LLM's outputs. This method is essentially a way of enriching our LLM prompt with relevant context of the holy text which the LLM should try to replicate for its own parable. We query our corpus through the following way.\n",
    "\n",
    "Given a `topic` (eg, \"forgiveness\"), we use HuggingFace's `all-MiniLM-L6-v2` transformer model to map the semantic meaning of the given phrase into an embedding vector. We then scan our `chromaDB` database of our given tradition's corpus, computing the cosine similarity between our `topic` and the stored parable-chunk, which are also stored as embeddings in this alternative vector space. We retrieve the `k` nearest matches, and then paste them into our final LLM prompt as \"context\" for the model to imitate the style of before generating its own parable that follows the user's other instructions.\n",
    "\n",
    "The LLM is given system instructions beforehand:\n",
    "```shell\n",
    "\"You are ParableGPT, generating a parable in the style of Christianity. \n",
    "Use a reverent, Biblical tone. \n",
    "Prefer simple, concrete imagery. \n",
    "Do not imitate any specific modern author.\n",
    "\n",
    "Write an original parable inspired by the provided sources; imitate the writing style closely. \n",
    "Do not quote long passages verbatim; paraphrase ideas instead. \n",
    "Target length: about 150 words.\n",
    "Begin with EXACTLY: 'Title: [insert_parable_title_here]'. \n",
    "End with EXACTLY: 'Moral: [insert_moral_here]'. Be concise.\"\n",
    "```\n",
    "\n",
    "Alongside the sample prompt:\n",
    "```shell\n",
    "\"Topic: Forgiveness\n",
    "\n",
    "User constraints (follow these carefully):\n",
    "Include a character named Brian Greene\n",
    "\n",
    "Relevant Bible passages (Imitate this tone and writing style as exactly as possible)\n",
    "\n",
    "Ezekiel 4:17-17\n",
    "That they may want bread and water, and be astonied one with another, and consume away for their iniquity.\n",
    "\n",
    "Now write the parable.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9e87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ollama import chat\n",
    "\n",
    "class ParableGPT:\n",
    "    def __init__(self, llm=\"llama3.1:8b\", embedder=\"all-MiniLM-L6-v2\"):\n",
    "        self.LLM_MODEL = llm\n",
    "        self.EMBEDDING_MODEL = SentenceTransformer(embedder)\n",
    "        self.DB_PATH = \"./corpus/chroma_db\"\n",
    "        self.client = chromadb.PersistentClient(self.DB_PATH)\n",
    "\n",
    "        # tradition-specific configuration variables\n",
    "        self.TRADITION_CONFIG = {\n",
    "            \"Christianity\": {\n",
    "                \"collection\": \"bible\",\n",
    "                \"style\": (\n",
    "                    \"Use a reverent, Biblical tone. \"\n",
    "                    \"Prefer simple, concrete imagery. \"\n",
    "                    \"Do not imitate any specific modern author.\"\n",
    "                ),\n",
    "                \"source_label\": \"Bible passages\",\n",
    "                \"ref_formatter\": lambda m: f'{m[\"book\"]} {m[\"chapter\"]}:{m[\"start_verse\"]}-{m[\"end_verse\"]}',\n",
    "            },\n",
    "            \"Buddhism\": {\n",
    "                \"collection\": \"dhammapada\",\n",
    "                \"style\": (\n",
    "                    \"Use a calm, concise, contemplative tone similar to the provided sources. \"\n",
    "                    \"Avoid sermonizing; let the lesson emerge naturally.\"\n",
    "                ),\n",
    "                \"source_label\": \"Dhammapada passages\",\n",
    "                \"ref_formatter\": lambda m: f'Dhammapada {m[\"chapter\"]} vv.{m[\"start_verse\"]}-{m[\"end_verse\"]}',\n",
    "            },\n",
    "            \"Islam\": {\n",
    "                \"collection\": \"quran\",\n",
    "                \"style\": (\n",
    "                    \"Use a poetic, rhythmic tone similar to the Quranic style. \"\n",
    "                    \"Incorporate vivid imagery and metaphors.\"\n",
    "                ),\n",
    "                \"source_label\": \"Quranic passages\",\n",
    "                \"ref_formatter\": lambda m: f'Surah {m[\"surah\"]} vv.{m[\"start_verse\"]}-{m[\"end_verse\"]}',\n",
    "            },\n",
    "            \"Taoism\": {\n",
    "                \"collection\": \"tao_te_ching\",\n",
    "                \"style\": (\n",
    "                    \"Use a simple, paradoxical, and poetic tone similar to the Tao Te Ching. \"\n",
    "                    \"Emphasize naturalness and spontaneity.\"\n",
    "                ),\n",
    "                \"source_label\": \"Tao Te Ching passages\",\n",
    "                \"ref_formatter\": lambda m: f'Chapter {m[\"chapter\"]}',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def retrieve(self, tradition, topic, k: int=6) -> tuple[list[str], list[dict]]:\n",
    "        \"\"\"Retrieves k relevant verses from the collection based on the topic\n",
    "        also returns relevant metadata such as book, chapter, verse number \n",
    "        (varies by tradition)\n",
    "\n",
    "        Args:\n",
    "            tradition (str): the tradition/collection to query from\n",
    "            topic (str): the topic to base the retrieval on\n",
    "            k (int, optional): number of verses to retrieve. Defaults to 6.\n",
    "        Returns:\n",
    "            tuple[list[str], list[dict]]: retrieved verses and their metadata\n",
    "        \"\"\"\n",
    "        theme_embeddings = self.EMBEDDING_MODEL.encode([topic], normalize_embeddings=True).tolist()\n",
    "        col = self.client.get_collection(name=self.TRADITION_CONFIG[tradition][\"collection\"])\n",
    "        results = col.query(\n",
    "            query_embeddings=theme_embeddings,\n",
    "            n_results=k,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        verses = results['documents'][0]\n",
    "        metadatas = results['metadatas'][0]\n",
    "        return verses, metadatas\n",
    "\n",
    "\n",
    "    def generate(self, tradition: str, topic: str, length: int=150, info: str=None, k: int=6) -> tuple[str, str]:\n",
    "        \"\"\"Generates a parable in the style of the specified tradition,\n",
    "        focusing on the given topic, length, and following any additional \n",
    "        instructions from the prompt.\n",
    "        \n",
    "        Args:\n",
    "            tradition (str): the tradition/style to emulate\n",
    "            topic (str): the topic/theme of the parable\n",
    "            length (int, optional): desired word count of the parable. Defaults to 150\n",
    "            info (str, optional): additional instructions for the parable. Defaults to None.\n",
    "        Returns:\n",
    "            tuple[str, str]: generated parable and the sources used\n",
    "        \"\"\"\n",
    "        # retrive relevant verses\n",
    "        verses, metadatas = self.retrieve(tradition, topic, k)\n",
    "        cfg = self.TRADITION_CONFIG[tradition]\n",
    "\n",
    "        # format sources\n",
    "        sources = []\n",
    "        for v, m in zip(verses, metadatas):\n",
    "            ref = cfg[\"ref_formatter\"](m)\n",
    "            sources.append(f\"{ref}\\n{v}\")\n",
    "        sources_text = \"\\n\\n\".join(sources)\n",
    "\n",
    "        # SYSTEM\n",
    "        system = (\n",
    "            f\"You are ParableGPT, generating a parable in the style of {tradition}. \"\n",
    "            f\"{cfg['style']} \"\n",
    "            \"Write an original parable inspired by the provided sources; imitate the writing style closely. \"\n",
    "            \"Do not quote long passages verbatim; paraphrase ideas instead. \"\n",
    "            f\"{f'Target length: about {length} words. ' if length!='' else ''}\"\n",
    "            \"Begin with EXACTLY: 'Title: [insert_parable_title_here]'. \"\n",
    "            \"End with EXACTLY: 'Moral: [insert_moral_here]'. Be concise.\"\n",
    "        )\n",
    "        # USER: topic + constraints\n",
    "        user = (\n",
    "            f\"Topic: {topic}\\n\\n\"\n",
    "            \"User constraints (follow these carefully):\\n\"\n",
    "            f\"{(info or \"\").strip()}\\n\\n\"\n",
    "            f\"Relevant {cfg['source_label']} \"\n",
    "            \"(Imitate this tone and writing style as exactly as possible)\"\n",
    "            # \"while following the Title: [insert_parable_title_here] and Moral: [insert_moral_here] format clearly.):\"\n",
    "            f\"\\n\\n{sources_text}\\n\\n\"\n",
    "            \"Now write the parable.\"\n",
    "        )\n",
    "        resp = chat(\n",
    "            model=self.LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": user}\n",
    "            ]\n",
    "        )\n",
    "        parable = resp[\"message\"][\"content\"]\n",
    "        return parable, sources\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Keep prompting user for input and generating parables until they quit.\n",
    "        \"\"\"\n",
    "        print(\"Welcome to ParableGPT!\\n\")\n",
    "        while True:\n",
    "            while True:\n",
    "                tradition_index = input(\"Select a tradition below or 'q' to quit: \\n\" \\\n",
    "                                        \" (0) Christianity\\n (1) Buddhism\\n\" \\\n",
    "                                        \" (2) Islam\\n (3) Taoism\\n\" \\\n",
    "                                        \"Your choice: \").strip()\n",
    "                if tradition_index.lower() == 'q':\n",
    "                    return\n",
    "                try:\n",
    "                    idx = int(tradition_index)\n",
    "                    if 0 <= idx < len(list(self.TRADITION_CONFIG.keys())):\n",
    "                        break\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                print(f\"Please enter a number 0-{len(list(self.TRADITION_CONFIG.keys()))-1}, or 'q'.\")\n",
    "\n",
    "            tradition = list(self.TRADITION_CONFIG.keys())[int(tradition_index)]\n",
    "            topic = input(\"Enter topic for the parable: \").strip()\n",
    "            length = input(\"Enter desired word count (enter to skip): \").strip()\n",
    "            info = input(\"Enter any additional instructions for the parable (enter to skip): \").strip()\n",
    "            parable, sources = self.generate(tradition, topic, length, info)\n",
    "            self.print_parable(parable, sources)\n",
    "\n",
    "    def print_parable(self, parable: str, sources: list[str]):\n",
    "        \"\"\"Prints the generated parable and its sources in a formatted way.\n",
    "\n",
    "        Args:\n",
    "            parable (str): The generated parable text.\n",
    "            sources (list[str]): List of source texts used for generation.\n",
    "        \"\"\"\n",
    "        print(\"\\n---\\n\")\n",
    "        print(parable)\n",
    "        print(\"\\n---\\n\")\n",
    "        print(\"SOURCES USED:\\n---\")\n",
    "        for s in sources:\n",
    "            print(s)\n",
    "            print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295910d",
   "metadata": {},
   "source": [
    "## Test it out!\n",
    "\n",
    "The following four code blocks show examples of running ParableGPT through this notebook—the results are printed below each. \n",
    "\n",
    "To use ParableGPT, just choose a tradition, a topic, a length (optional), and additional info (optional), and wait ~40 seconds for the parable to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8136d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "Title: The Empty Pot\n",
      "\n",
      "There was a village nestled in a valley where hunger had become a constant companion. In this village lived Brian Greene, a humble farmer who struggled to provide for his family. One day, as he labored in his field, a stranger approached him with a gift of bread and vegetables.\n",
      "\n",
      "The stranger said, \"Brian, I have seen your struggles and the emptiness in your pot. Take this food and share it with your people, that they may eat and be satisfied.\" Brian was hesitant at first, but the stranger assured him, \"Trust in my provision, for He who gives food to all flesh will also provide for you.\"\n",
      "\n",
      "As Brian distributed the food, he watched as his neighbors ate until they were full, and then some. The pot was empty, yet there was still enough for everyone. A miracle had occurred.\n",
      "\n",
      "Moral: Trust in God's provision, and He will supply your needs, that you may eat and be satisfied, and share with others to the glory of His mercy.\n",
      "\n",
      "---\n",
      "\n",
      "SOURCES USED:\n",
      "---\n",
      "Ezekiel 4:17-17\n",
      "That they may want bread and water, and be astonied one with another, and consume away for their iniquity.\n",
      "\n",
      "1 Corinthians 11:33-34\n",
      "Wherefore, my brethren, when ye come together to eat, tarry one for another. And if any man hunger, let him eat at home; that ye come not together unto condemnation. And the rest will I set in order when I come.\n",
      "\n",
      "Job 38:41-41\n",
      "Who provideth for the raven his food? when his young ones cry unto God, they wander for lack of meat.\n",
      "\n",
      "Proverbs 13:25-25\n",
      "The righteous eateth to the satisfying of his soul: but the belly of the wicked shall want.\n",
      "\n",
      "Psalm 136:25-26\n",
      "Who giveth food to all flesh: for his mercy endureth for ever. O give thanks unto the God of heaven: for his mercy endureth for ever.\n",
      "\n",
      "2 Kings 4:41-44\n",
      "But he said, Then bring meal. And he cast it into the pot; and he said, Pour out for the people, that they may eat. And there was no harm in the pot. And there came a man from Baalshalisha, and brought the man of God bread of the firstfruits, twenty loaves of barley, and full ears of corn in the husk thereof. And he said, Give unto the people, that they may eat. And his servitor said, What, should I set this before an hundred men? He said again, Give the people, that they may eat: for thus saith the Lord, They shall eat, and shall leave thereof. So he set it before them, and they did eat, and left thereof, according to the word of the Lord.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parable_gpt = ParableGPT()\n",
    "p1, s1 = parable_gpt.generate(\n",
    "    tradition=\"Christianity\",\n",
    "    topic=\"Hunger\",\n",
    "    # length=150, # words\n",
    "    info=\"Include a character named 'Brian Greene'\",\n",
    "    k=6\n",
    ")\n",
    "parable_gpt.print_parable(p1, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98aaf277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "Title: The Island of Desire\n",
      "\n",
      "Brian Greene was a wealthy merchant who had built his fortune on the shores of a vast lake. He spent his days accumulating more wealth, thinking that it would bring him happiness and security. One day, as he stood at the edge of the lake, watching the sun set behind the hills, he felt a sense of emptiness within. He realized that despite all his possessions, he was still unsatisfied.\n",
      "\n",
      "A wise old man appeared beside him, pointing to a small island in the distance. \"Brian, you have built a grand house on the shore,\" said the old man, \"but what about an inner refuge from desire? What about peace of mind?\" Brian looked puzzled, but the old man continued, \"You see, my friend, our desires are like waves that crash against the shore. They never truly satisfy us, and yet we keep striving for more.\"\n",
      "\n",
      "Brian thought about this for a moment, then asked, \"But how can I stop these waves? How can I find peace?\" The old man smiled, saying, \"Ah, Brian, you must learn to recognize the rust that corrodes your heart. It is ignorance of your true nature, and it will lead you further into suffering. Make an island for yourself by letting go of attachment and craving. Strive quickly; be wise!\"\n",
      "\n",
      "Moral: The pursuit of material wealth and desire can never bring lasting peace, but rather leads to greater suffering.\n",
      "\n",
      "---\n",
      "\n",
      "SOURCES USED:\n",
      "---\n",
      "Dhammapada Impurity vv.235-255\n",
      "You are now like a withered leaf, and even death's messengers await you. You stand at departure's threshold, but you have no provisions for the journey. Make an island for yourself! Strive quickly; be wise! Purged of stain and flawless, you will reach the noble land of the gods. Your life has come to an end now; you are setting forth into the presence of Yama, the king of death, and there is no resting place for you on the way, nor have you any provisions for the journey. Make an island for yourself! Strive quickly; be wise! Purged of stain and flawless, you will not come again to birth and decay. Little by little, bit by bit, moment by moment, a wise man should remove his own impurities, as a smith removes his dross from silver. As rust arising from iron eats away the very iron from which it arose, even so do their own deeds lead transgressors to states of woe. Non-recitation is the rust of mantras; non-exertion is the rust of homes; sloth is the rust of beauty; carelessness is the rust of a guard. Misconduct is the rust of a woman; stinginess is the rust of a giver; evil deeds are rust in this world and the next. But there is a rust worse than all these rusts—ignorance is the greatest rust. O monks! Cast away this rust and be free from stain! Life is easy to live for a man who is without shame, a crow hero, a mischief-maker, an insulting, bold, and wretched fellow. But life is hard to live for a modest man, who always seeks for what is pure, who is disinterested, quiet, spotless, and intelligent. He who destroys life, utters lies, takes what is not given to him, goes to another man's wife, and the man who gives himself to drinking intoxicating liquors, he, even in this world, digs up his own root. O man, know this, that the unrestrained are in a bad state; take care that greediness and vice do not bring thee to grief for a long time! The world gives according to their faith or according to their pleasure: if a man frets about the food and the drink given to others, he will not attain concentration, either by day or by night. He in whom that feeling is destroyed, and taken out with the very root, finds rest by day or by night. There is no fire like passion, there is no losing throw like hatred, there is no pain like this body, there is no happiness higher than rest. Hunger is the worst of diseases, the body the greatest of pains; if one knows this truly, that is Nibbāna, the highest happiness. Health is the greatest of gifts, contentedness the best riches; trust is the best of relationships, Nibbāna the highest happiness. He who has tasted the sweetness of solitude and tranquillity, is free from fear and free from sin, while he tastes the sweetness of drinking in the law. The sight of the noble is good, to live with them is always happiness; if a man does not see fools, he will be truly happy.\n",
      "\n",
      "Dhammapada Affection vv.209-220\n",
      "Apply yourself to what should not be done; do not apply yourself to what should be done. The slothful who cling to the pleasant miss the goal, while others reach it. From attachment springs grief, from attachment springs fear. For one who is wholly free from attachment there is no grief, and whence can fear come? From affection springs grief, from affection springs fear. For one who is wholly free from affection there is no grief, and whence can fear come? From pleasure springs grief, from pleasure springs fear. For one who is wholly free from pleasure there is no grief, and whence can fear come? From lust springs grief, from lust springs fear. For one who is wholly free from lust there is no grief, and whence can fear come? From craving springs grief, from craving springs fear. For one who is wholly free from craving there is no grief, and whence can fear come? People hold dear one who is endowed with virtue and insight, who is principled, has realized the truth, and who himself does what he ought to be doing. One who has developed a wish for the Undeclared (Nibbāna), who is filled with longing, and whose mind is not bound by material pleasures, is called 'bound upstream.' When, after a long absence, a man returns safely from afar, his kinsmen, friends, and well-wishers welcome him back. In the same way, when a man who has done good deeds goes from this world to the next, his good deeds receive him there, as kinsmen welcome a dear one on his return. Having slain mother (craving), father (conceit), two warrior-kings (eternalism and nihilism), and destroyed a country (sense-objects) together with its treasurer (attachment), ungrieving goes the holy man. Having slain mother, father, two learned kings, and a tiger as the fifth (the five hindrances), ungrieving goes the holy man.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2, s2 = parable_gpt.generate(\n",
    "    tradition=\"Buddhism\",\n",
    "    topic=\"Materialism\",\n",
    "    length=150, # words\n",
    "    info=\"Include a character named 'Brian Greene'\",\n",
    "    k=2\n",
    ")\n",
    "parable_gpt.print_parable(p2, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12acb6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "Title: The Shadow of Shame\n",
      "\n",
      "In a small village nestled between two great rivers, there lived a man named Brian Greene. He was known throughout the land for his extraordinary talent in weaving intricate patterns on silk fabric. However, despite his skill, Brian was consumed by the shadow of shame.\n",
      "\n",
      "One day, while working on a particularly delicate design, he accidentally dropped a valuable thread, which fell into the river below. The villagers, who had gathered to witness his work, gasped in horror as the thread was carried away by the current. Brian's face turned bright red with mortification, and he hid his head in shame.\n",
      "\n",
      "The Prophet of the village, seeing Brian's distress, approached him and said, \"O Brian, do you know that the rivers are a reminder of Allah's mercy? Just as they flow constantly, cleansing all that comes before them, so too does Allah forgive and cleanse those who repent.\"\n",
      "\n",
      "Brian looked up, his eyes brimming with tears. \"But, revered one,\" he asked, \"how can I overcome this shame? It feels like a weight upon me, impossible to bear.\"\n",
      "\n",
      "The Prophet smiled and said, \"Just as the rivers have banks that prevent them from overflowing, so too do you have within yourself the power to contain your emotions. Remember that Allah's mercy is greater than any shame or guilt you may feel.\"\n",
      "\n",
      "Brian took the Prophet's words to heart, and with each passing day, he learned to let go of his shame and focus on his craft. As he did, his patterns grew more beautiful, and his reputation as a master weaver spread far and wide.\n",
      "\n",
      "One day, the villagers gathered once more to witness Brian's work. This time, however, they saw not a man consumed by shame, but one radiating joy and confidence. The Prophet smiled upon him and said, \"Behold, O Brian, how Allah's mercy has lifted your shadow of shame.\"\n",
      "\n",
      "Moral: The shadow of shame can be lifted only through the power of Allah's mercy and forgiveness, which is always available to those who seek it with a sincere heart.\n",
      "\n",
      "---\n",
      "\n",
      "SOURCES USED:\n",
      "---\n",
      "Surah 48 vv.17-28\n",
      "There is not upon the blind any guilt or upon the lame any guilt or upon the ill any guilt [for remaining behind]. And whoever obeys Allah and His Messenger - He will admit him to gardens beneath which rivers flow; but whoever turns away - He will punish him with a painful punishment Certainly was Allah pleased with the believers when they pledged allegiance to you, [O Muhammad], under the tree, and He knew what was in their hearts, so He sent down tranquillity upon them and rewarded them with an imminent conquest And much war booty which they will take. And ever is Allah Exalted in Might and Wise Allah has promised you much booty that you will take [in the future] and has hastened for you this [victory] and withheld the hands of people from you - that it may be a sign for the believers and [that] He may guide you to a straight path And [He promises] other [victories] that you were [so far] unable to [realize] which Allah has already encompassed. And ever is Allah, over all things, competent And if those [Makkans] who disbelieve had fought you, they would have turned their backs [in flight]. Then they would not find a protector or a helper [This is] the established way of Allah which has occurred before. And never will you find in the way of Allah any change And it is He who withheld their hands from you and your hands from them within [the area of] Makkah after He caused you to overcome them. And ever is Allah of what you do, Seeing They are the ones who disbelieved and obstructed you from al-Masjid al-Haram while the offering was prevented from reaching its place of sacrifice. And if not for believing men and believing women whom you did not know - that you might trample them and there would befall you because of them dishonor without [your] knowledge - [you would have been permitted to enter Makkah]. [This was so] that Allah might admit to His mercy whom He willed. If they had been apart [from them], We would have punished those who disbelieved among them with painful punishment When those who disbelieved had put into their hearts chauvinism - the chauvinism of the time of ignorance. But Allah sent down His tranquillity upon His Messenger and upon the believers and imposed upon them the word of righteousness, and they were more deserving of it and worthy of it. And ever is Allah, of all things, Knowing Certainly has Allah showed to His Messenger the vision in truth. You will surely enter al-Masjid al-Haram, if Allah wills, in safety, with your heads shaved and [hair] shortened, not fearing [anyone]. He knew what you did not know and has arranged before that a conquest near [at hand] It is He who sent His Messenger with guidance and the religion of truth to manifest it over all religion. And sufficient is Allah as Witness\n",
      "\n",
      "Surah 71 vv.9-20\n",
      "Then I announced to them and [also] confided to them secretly And said, 'Ask forgiveness of your Lord. Indeed, He is ever a Perpetual Forgiver He will send [rain from] the sky upon you in [continuing] showers And give you increase in wealth and children and provide for you gardens and provide for you rivers What is [the matter] with you that you do not attribute to Allah [due] grandeur While He has created you in stages Do you not consider how Allah has created seven heavens in layers And made the moon therein a [reflected] light and made the sun a burning lamp And Allah has caused you to grow from the earth a [progressive] growth Then He will return you into it and extract you [another] extraction And Allah has made for you the earth an expanse That you may follow therein roads of passage\n",
      "\n",
      "Surah 51 vv.57-60\n",
      "I do not want from them any provision, nor do I want them to feed Me Indeed, it is Allah who is the [continual] Provider, the firm possessor of strength And indeed, for those who have wronged is a portion [of punishment] like the portion of their predecessors, so let them not impatiently urge Me And woe to those who have disbelieved from their Day which they are promised\n",
      "\n",
      "Surah 53 vv.57-62\n",
      "The Approaching Day has approached Of it, [from those] besides Allah, there is no remover Then at this statement do you wonder And you laugh and do not weep While you are proudly sporting So prostrate to Allah and worship [Him]\n",
      "\n",
      "Surah 83 vv.33-36\n",
      "But they had not been sent as guardians over them So Today those who believed are laughing at the disbelievers On adorned couches, observing Have the disbelievers [not] been rewarded [this Day] for what they used to do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3, s3 = parable_gpt.generate(\n",
    "    tradition=\"Islam\",\n",
    "    topic=\"Shame\",\n",
    "    length=150, # words\n",
    "    info=\"Include a character named 'Brian Greene'\",\n",
    "    k=5\n",
    ")\n",
    "parable_gpt.print_parable(p3, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d7021ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "Title: Brian's Dance with the Way\n",
      "\n",
      "Brian Greene, a renowned physicist, stood on the mountaintop, gazing out at the vast expanse of the universe. He had spent his life studying the intricacies of time and space, but never truly grasped the essence of the Way.\n",
      "\n",
      "As he pondered, a gentle breeze rustled his hair, and he felt an inexplicable urge to dance. With each step, he surrendered to the moment, letting go of his need for control and understanding. The world around him dissolved into chaos, yet somehow coalesced into harmony.\n",
      "\n",
      "A passerby, observing Brian's spontaneous dance, laughed out loud at the absurdity of it all. \"The master is a fool!\" they jeered. Yet, as the onlooker joined in, their own steps blended with the rhythm of the universe, and together they swayed like reeds in a gentle stream.\n",
      "\n",
      "Brian Greene, lost in the dance, became one with the Way. His laughter merged with the vital breath, and his being harmonized with the cosmos. In that moment, he transcended duality, embracing both yin and yang within himself.\n",
      "\n",
      "Moral: The highest virtue is not something to be sought; it arises from surrendering to the ever-changing present.\n",
      "\n",
      "---\n",
      "\n",
      "SOURCES USED:\n",
      "---\n",
      "Chapter 41\n",
      "The superior student listens to the Way\n",
      "And follows it closely.\n",
      "The average student listens to the Way\n",
      "And follows some and some not.\n",
      "The lesser student listens to the Way\n",
      "And laughs out loud.\n",
      "If there were no laughter it would not be the Way.\n",
      "So, it has been said:\n",
      "The light of the Way seems dim.\n",
      "The progress of the Way seems retreating.\n",
      "The straightness of the Way seems curved.\n",
      "The highest virtue seems as low as a valley.\n",
      "The purest white seems stained.\n",
      "The grandest virtue seems deficient.\n",
      "The sturdiest virtue seems fragile.\n",
      "The most fundamental seems fickle.\n",
      "The perfect square lacks corners.\n",
      "The greatest vessel takes long to complete.\n",
      "The highest tone is hard to hear.\n",
      "The great image lacks shape.\n",
      "The Way is hidden and nameless.\n",
      "Still only the Way nourishes and completes.\n",
      "\n",
      "Chapter 62\n",
      "The Way is the source of all things,\n",
      "Good people's treasure and bad people's refuge.\n",
      "Fine words are traded.\n",
      "Noble deeds gain respect.\n",
      "But people who are not good,\n",
      "Why abandon them?\n",
      "So, when the emperor is crowned\n",
      "Or the three dukes are appointed,\n",
      "Rather than sending a gift of jade\n",
      "Carried by four horses,\n",
      "Remain still and offer the Way.\n",
      "Why did the ancients praise the Way?\n",
      "Did they not say it was because you find what you seek\n",
      "And are saved from your wrongdoings?\n",
      "That is why the world praises it.\n",
      "\n",
      "Chapter 42\n",
      "The Way gave birth to one.\n",
      "One gave birth to two.\n",
      "Two gave birth to three.\n",
      "Three gave birth to all things.\n",
      "All things carry yin and embrace yang.\n",
      "They reach harmony by blending with the vital breath.\n",
      "What people loathe the most\n",
      "Is to be orphaned, desolate, unworthy.\n",
      "But this is what princes and kings call themselves.\n",
      "Sometimes gain comes from losing,\n",
      "And sometimes loss comes from gaining.\n",
      "What others have taught, I also teach:\n",
      "The forceful and violent will not die from natural causes.\n",
      "This will be my chief doctrine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4, s4 = parable_gpt.generate(\n",
    "    tradition=\"Taoism\",\n",
    "    topic=\"The Way\",\n",
    "    length=150, # words\n",
    "    info=\"Include a character named 'Brian Greene'\",\n",
    "    k=3\n",
    ")\n",
    "parable_gpt.print_parable(p4, s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8159b2",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "What went well:\n",
    "- The outputs were more coherent than I expected a 8B parameter language model to perform. Stories were more or less logical, at the least.\n",
    "- The Dhammapada and Tao Te Ching were already in an ideal format for parable-like analysis.\n",
    "- It was fun to conjure up random stories that miraculously tied back to some moralistic meaning.\n",
    "\n",
    "For the future, I would want to:\n",
    "- Include more relevant stylistic instructions for the LLM\n",
    "- Use a model with more parameters for higher quality output\n",
    "- Cleanup the Bible texts to only include sections with parables\n",
    "- Add more religions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e5fe7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
